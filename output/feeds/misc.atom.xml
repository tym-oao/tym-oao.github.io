<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>TYM engineering notes</title><link href="/" rel="alternate"></link><link href="/feeds/misc.atom.xml" rel="self"></link><id>/</id><updated>2016-06-29T22:54:20+00:00</updated><entry><title>Corrupt database disk issue at GCE</title><link href="/corrupt-database-disk-issue-at-gce.html" rel="alternate"></link><published>2016-06-29T22:54:20+00:00</published><author><name>Thomas</name></author><id>tag:,2016-06-29:corrupt-database-disk-issue-at-gce.html</id><summary type="html">&lt;p&gt;Posting this here mainly in case this issue happens to come up again. I've noticed several cases in recent cloud console Notification Activity in which repeated disk-attachment errors were reported. In those cases I didn't notice any database service outages, but this still seems like something that could end up not being an isolated incident.&lt;/p&gt;
&lt;h3&gt;Problem&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Between 22:10 and 22:20 on 2016-06-29, the Google cloud console Activity record shows that the persistent disks mounted to nodes in the &lt;code&gt;warehouse-provisioning-1&lt;/code&gt; k8s cluster detached themselves from the instances they had been attached to.&lt;/li&gt;
&lt;li&gt;I say "detached themselves" because neither myself nor anyone at OAO executed any k8s commands to explicitly detach them. The root cause for the detachment is uncertain.&lt;/li&gt;
&lt;li&gt;The timing of &lt;a href="https://status.cloud.google.com/incident/compute/16011"&gt;this SSD latency incident incident&lt;/a&gt; from the GCE &lt;a href="https://status.cloud.google.com"&gt;status page&lt;/a&gt; seems to coincide with when these detachments happened. I imagine that disks might have had to be detached and reattached as part of whatever Google engineers did to resolve the issue, but that's a guess on my part.&lt;/li&gt;
&lt;li&gt;In any case, while the disks were also automatically reattached, the abrupt disconnection left them in an inconsistent state, so that Postgres instances which use these disk mounts for storage were unable to start due to I/O errors.&lt;/li&gt;
&lt;li&gt;Result: &lt;code&gt;warehouse-postgres&lt;/code&gt; and &lt;code&gt;mart-postgres&lt;/code&gt; instances were down since roughly 22:19.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Resolution&lt;/h3&gt;
&lt;p&gt;Basically, to get things working again, I had to &lt;code&gt;fsck&lt;/code&gt; the affected disks, then detach them from the instances they were attached to with a &lt;code&gt;gcloud&lt;/code&gt; command. So, for example, in the case of the disk &lt;code&gt;mart-data-disk&lt;/code&gt; attached to &lt;code&gt;warehouse-provisioning-1-fde62020-node-8n9r&lt;/code&gt; I had to:&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3
4&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ssh warehouse-provisioning-1-fde62020-node-8n9r &lt;span class="se"&gt;\&lt;/span&gt;
sudo fsck.ext4 -v -y /dev/disk/by-id/google
gcloud compute instances detach-disk &lt;span class="se"&gt;\&lt;/span&gt;
gke-warehouse-provisioning-1-fde62020-node-8n9r --disk mart-data-disk
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;Then restart the &lt;code&gt;mart-postgres&lt;/code&gt; as usual with &lt;code&gt;kubectl create -f mart-postgres.yaml&lt;/code&gt;.&lt;/p&gt;</summary></entry><entry><title>Self-referential TODO</title><link href="/self-referential-todo.html" rel="alternate"></link><published>2016-06-23T07:24:35-05:00</published><author><name>Thomas</name></author><id>tag:,2016-06-23:self-referential-todo.html</id><summary type="html">&lt;p&gt;&lt;s&gt;While I want to keeping the styling and build of this page brutally simple, one thing I should consider adding is &lt;a href="http://pygments.org/"&gt;pygments&lt;/a&gt; or similar for code syntax highlighting.&lt;/s&gt; &lt;em&gt;(UPDATE: done!)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;s&gt;Also, look into why &lt;a href="https://github.com/yagermadden/straplessdown"&gt;straplessdown&lt;/a&gt; is stripping inline HTML from the markdown source section. ðŸ˜• &lt;/s&gt; &lt;em&gt;(UPDATE: wontfix; using Pelican now instead.)&lt;/em&gt;&lt;/p&gt;</summary></entry><entry><title>Distinct line items from DFP line item service</title><link href="/distinct-line-items-from-dfp-line-item-service.html" rel="alternate"></link><published>2016-05-18T00:00:00-05:00</published><author><name>Thomas</name></author><id>tag:,2016-05-18:distinct-line-items-from-dfp-line-item-service.html</id><summary type="html">&lt;p&gt;Over time, the table &lt;code&gt;warehouse_hold.hold_dfp_line_item&lt;/code&gt; has accumulated many rows for each line item. In most cases this is due to changes in the line item configuration or status; it is also due to overlapping attempts to bring the data up-to-date. In any case, Analytics is interested only in the most recent record for each item. As noted in &lt;a href="https://trello.com/c/ygfrMXJr/615-warehouse-etl-investigate-and-fix-line-item-discrepancies-between-dfp-and-hold-dfp-line-item-table"&gt;Trello&lt;/a&gt;, I created a new &lt;code&gt;hold_dfp_line_item_distinct&lt;/code&gt; table, to include one record per line_item_id, based on maximum &lt;code&gt;last_modified_date_time&lt;/code&gt; and &lt;code&gt;created_at&lt;/code&gt; values.&lt;/p&gt;
&lt;p&gt;Oddly (says I), while a CTE defined as&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3
4
5&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;select&lt;/span&gt; &lt;span class="k"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_modified_date_time&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;last_modified_date_time&lt;/span&gt;
     &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;created_at&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;created_at&lt;/span&gt;
     &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line_item_id&lt;/span&gt;
  &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="n"&gt;hold_dfp_line_item&lt;/span&gt;
 &lt;span class="k"&gt;group&lt;/span&gt; &lt;span class="k"&gt;by&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;has the expected number of rows, joining that on all three columns back to the main table resulted in a small number (39 out of about a million) of duplicate rows.&lt;/p&gt;
&lt;p&gt;I have been able to resolve the matter by using &lt;code&gt;select distinct&lt;/code&gt;  in the main query, but I don't understand why it should be necessary.&lt;/p&gt;
&lt;p&gt;Also, as we update with new pulls from the line item service, we'll begin to have multiple rows per line item again, and if this simplified table is desirable in Hold, we'll have to keep refreshing it. Therefore, we will eventually find out whether the duplication of the same line item at the same created_at timestamp was a one-time glitch, or something ongoing. In the former case, we should remove the &lt;code&gt;distinct&lt;/code&gt; from the query, for performance reasons. This note is here as a reminder&lt;/p&gt;</summary></entry><entry><title>Handling fact updates</title><link href="/handling-fact-updates.html" rel="alternate"></link><published>2016-05-11T07:24:35-05:00</published><author><name>Thomas</name></author><id>tag:,2016-05-11:handling-fact-updates.html</id><summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href="http://decisionworks.com/2010/12/design-tip-130-accumulating-snapshots-for-complex-workflows/"&gt;Accumulating snapshot&lt;/a&gt; fact table pattern sounded attractive, but we cannot apply it to our case. It is a way of handling late-arriving facts, but supposes access to the transactional workflow milestone data.&lt;/li&gt;
&lt;li&gt;In our case, DFP is already returning us pre-aggregated snapshot data; they restate the snapshot data over time as more atomic data accumulates on their end.&lt;/li&gt;
&lt;li&gt;For this reason, the best approach will be to reload over a reasonable window to keep our fact table records current with the latest stated values from DFP&lt;/li&gt;
&lt;li&gt;Exact number of days in the window TBD based on analysis of recent re-pulls of data we have already loaded.&lt;/li&gt;
&lt;li&gt;Best guess as of now: 14-day reload window (requires further investigation to rule out first-of-month being exceptional)&lt;/li&gt;
&lt;/ul&gt;</summary></entry><entry><title>Slowly-changing dimension handling for dim_line_item</title><link href="/slowly-changing-dimension-handling-for-dim_line_item.html" rel="alternate"></link><published>2016-05-09T00:00:00-05:00</published><author><name>Thomas</name></author><id>tag:,2016-05-09:slowly-changing-dimension-handling-for-dim_line_item.html</id><summary type="html">&lt;ul&gt;
&lt;li&gt;Hold table load is somewhat incremental already: all modified items get added on to the hold table (not really distinguished from prior versions, but we can use &lt;code&gt;last_modified_date_time&lt;/code&gt; for that)&lt;/li&gt;
&lt;li&gt;So, pull for &lt;code&gt;dim_line_item&lt;/code&gt; update begins by taking all records with most recent &lt;code&gt;created_at&lt;/code&gt; timestamps from &lt;code&gt;hold_dfp_line_item&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;These can be inserted directly to &lt;code&gt;dim_line_item&lt;/code&gt;, with &lt;code&gt;current_date&lt;/code&gt; as &lt;code&gt;effective_dt&lt;/code&gt; and &lt;code&gt;created_at&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Then find &lt;code&gt;line_item_code&lt;/code&gt; values that match newly-inserted rows, with prior &lt;code&gt;created_at&lt;/code&gt; and NULL &lt;code&gt;effective_end_dt&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;update &lt;code&gt;effective_end_dt&lt;/code&gt; of those rows with current_date&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;: treat line_item_code as the fixed SCD key; treat change in any other column as requiring a new record.&lt;/li&gt;
&lt;/ul&gt;</summary></entry></feed>