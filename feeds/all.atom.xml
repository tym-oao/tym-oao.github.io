<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>TYM engineering notes</title><link href="/" rel="alternate"></link><link href="/feeds/all.atom.xml" rel="self"></link><id>/</id><updated>2016-07-19T03:31:03+00:00</updated><entry><title>Stackdriver</title><link href="/stackdriver.html" rel="alternate"></link><published>2016-07-19T03:31:03+00:00</published><author><name>Thomas</name></author><id>tag:,2016-07-19:stackdriver.html</id><summary type="html">&lt;p&gt;I've studying [Stackdriver Monitoring] for Google Cloud, and setting up a few simple alerts and metric dashboards. I wrote up my findings on &lt;a href="https://github.com/tym-oao/tym-oao.github.io/wiki/Stackdriver-Monitoring"&gt;this wiki page&lt;/a&gt;.&lt;/p&gt;</summary></entry><entry><title>Using pg_service.conf with Luigi</title><link href="/using-pg_serviceconf-with-luigi.html" rel="alternate"></link><published>2016-07-14T17:42:15+00:00</published><author><name>Thomas</name></author><id>tag:,2016-07-14:using-pg_serviceconf-with-luigi.html</id><summary type="html">&lt;p&gt;I was thinking about the pg_service.conf post I wrote yesterday, and wondering how to follow that practice in &lt;a href="http://luigi.readthedocs.io/"&gt;Luigi&lt;/a&gt;. It's a little tricky, because &lt;a href="http://luigi.readthedocs.io/en/stable/api/luigi.postgres.html"&gt;&lt;code&gt;luigi.postgres&lt;/code&gt;&lt;/a&gt; implements instances of &lt;code&gt;luigi.contrib.rdbms&lt;/code&gt; abstract classes, and therefore expects all the abstract properties (i.e., host, database, etc.) to be specified. So, when I tried simply overriding the &lt;code&gt;connect()&lt;/code&gt; method of &lt;code&gt;PostgresTarget&lt;/code&gt; I was getting TypeErrors because those abstract methods weren't implemented.&lt;/p&gt;
&lt;p&gt;I didn't want to build this up from a generic Luigi &lt;code&gt;Task&lt;/code&gt;, because &lt;code&gt;luigi.postgres&lt;/code&gt; and &lt;code&gt;luigi.contrib.rdbms&lt;/code&gt; have a lot of really useful stuff already implemented that I would have had to repeat for myself. In the end, I found that I could just set the &lt;code&gt;rdms&lt;/code&gt; properties to &lt;code&gt;None&lt;/code&gt; defaults and then ignore them, while overriding &lt;code&gt;PostgresTarget.connect()&lt;/code&gt; the way I wanted to. The resulting template tasks, along with a couple of simple examples of subclassing them for specific jobs are in &lt;a href="https://gist.github.com/yagermadden/d515f0b1dde2c4cdd6c192e08bb33e00"&gt;this Gist&lt;/a&gt; which is also shown below:&lt;/p&gt;
&lt;div class="gist"&gt;
    &lt;script src='https://gist.github.com/d515f0b1dde2c4cdd6c192e08bb33e00.js'&gt;&lt;/script&gt;
    &lt;noscript&gt;
        &lt;pre&gt;&lt;code&gt;import luigi
import luigi.postgres
import psycopg2

testdata = ([99, 'My fake plants died because I did not pretend to water'
             ' them.'],
            [100, 'I always arrive late at the office, '
            'but I make up for it by leaving early.'],
            [101, u'‚à© ‚à™'])


class PgServiceTarget(luigi.postgres.PostgresTarget):
    """
    Target for a resource in PostgreSQL, overriding the standard PostgresTarget
    to use a pg_service.conf service name to make the connection instead of
    separate connection params
    """
    def __init__(self, service, update_id, table):
        """
        Args:
            service (str): the name of a service defined in local
                pg_service.conf file
            update_id (str): An identifier for this data set
        """
        self.service = service
        self.update_id = update_id
        self.table = table

    def connect(self):
        """
        Get a psycopg2 connection object to the database where the table is.
        """
        connection = psycopg2.connect(
            service=self.service)
        connection.set_client_encoding('utf-8')
        return connection


class PgServiceQuery(luigi.postgres.PostgresQuery):
    """
    Template task for querying a PostgreSQL database, with standard output
    method overridden to return a PgServiceTarget
    """
    # Handle the properties expected by abstract class rdbms.Query
    host = None
    database = None
    user = None
    password = None

    def output(self):
        return PgServiceTarget(service=self.service, table=self.table, update_id=self.update_id)


class PgCopyToTable(luigi.postgres.CopyToTable):
    """
    Template task for inserting a data set into Postgres via PgServiceTarget
    """
    # Handle the properties expected by abstract class rdbms.Query
    host = None
    database = None
    user = None
    password = None

    def output(self):
        return PgServiceTarget(service=self.service, table=self.table, update_id=self.update_id)


class PgExampleQuery(PgServiceQuery):
    service = luigi.Parameter(default='local')
    table = 'whoa'
    query = 'create table whoa (trival_id serial, whoa_txt text)'


class PgExampleLoad(PgCopyToTable):
    service = luigi.Parameter(default='local')
    table = 'whoa'
    columns = [("trival_id", "INT"),
               ("description", "TEXT")]

    def rows(self):
        for record in testdata:
            yield record
&lt;/code&gt;&lt;/pre&gt;
    &lt;/noscript&gt;
&lt;/div&gt;</summary></entry><entry><title>pg_service + psycopg2 = ‚ù§Ô∏è</title><link href="/pg_service-psycopg2.html" rel="alternate"></link><published>2016-07-13T16:13:30+00:00</published><author><name>Thomas</name></author><id>tag:,2016-07-13:pg_service-psycopg2.html</id><summary type="html">&lt;p&gt;A couple of days ago I learned about the &lt;a href="https://www.postgresql.org/docs/current/static/libpq-pgservice.html"&gt;pg_service.conf file&lt;/a&gt; in Postgres, and posted about it to my teammates in Slack. It lets you store connection parameters under single service names, using square-bracked "INI file" format. This makes connecting to frequently-used hosts and databases much easier. For example, with a &lt;code&gt;pg_service.conf&lt;/code&gt; like...&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3
4
5&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[mydb]&lt;/span&gt;
&lt;span class="na"&gt;host&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;somehost&lt;/span&gt;
&lt;span class="na"&gt;port&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;5433&lt;/span&gt;
&lt;span class="na"&gt;user&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;someuser&lt;/span&gt;
&lt;span class="na"&gt;dbname&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;mydatabase&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;...then you can go &lt;code&gt;PGSERVICE=mydb psql&lt;/code&gt; at the command line, and Bob's your uncle. (This is extra handy if you have the &lt;code&gt;PGPASSWORD&lt;/code&gt; envar set to the password for &lt;code&gt;someuser&lt;/code&gt;.) Instead of always setting the PGSERVICE variable, I also export that to my most-often-used service (the warehouse instance, in my case) in my &lt;code&gt;.bashrc&lt;/code&gt;. Another way I made this easier on myself is with by adding a simple alias-like function (I used a function because aliases can't take arguments):&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pg&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="nv"&gt;PGSERVICE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt; psql

&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;The other noteworthy thing here, is that the defined services work at the libpq level, which means that any native postgresql driver (for instance psycopg2 üòâ) can use them as well.&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;psycopg2&lt;/span&gt;

&lt;span class="n"&gt;conn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;psycopg2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;connect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;service&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;mydb&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;password&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;secret&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# or set PGPASSWORD&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;I made a more complete example in &lt;a href="https://gist.github.com/tym-oao/33baf67bb332cebc4b20f7211dbedf59"&gt;this gist&lt;/a&gt;. I suggest we should use this manner of provisioning database connections as a matter of policy:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ADD&lt;/code&gt; a pg_service.conf file to your Docker image (likely better: provide for one to be mounted in at run time).&lt;/li&gt;
&lt;li&gt;Use Kubernetes secret to set &lt;code&gt;PGPASSWORD&lt;/code&gt; in the environment&lt;/li&gt;
&lt;li&gt;Pass the service name to the psycopg2 (or whichever driver) connection method&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It just makes sense.&lt;/p&gt;</summary></entry><entry><title>Corrupt database disk issue at GCE</title><link href="/corrupt-database-disk-issue-at-gce.html" rel="alternate"></link><published>2016-06-29T22:54:20+00:00</published><author><name>Thomas</name></author><id>tag:,2016-06-29:corrupt-database-disk-issue-at-gce.html</id><summary type="html">&lt;p&gt;Posting this here mainly in case this issue happens to come up again. I've noticed several cases in recent cloud console Notification Activity in which repeated disk-attachment errors were reported. In those cases I didn't notice any database service outages, but this still seems like something that could end up not being an isolated incident.&lt;/p&gt;
&lt;h3&gt;Problem&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Between 22:10 and 22:20 on 2016-06-29, the Google cloud console Activity record shows that the persistent disks mounted to nodes in the &lt;code&gt;warehouse-provisioning-1&lt;/code&gt; k8s cluster detached themselves from the instances they had been attached to.&lt;/li&gt;
&lt;li&gt;I say "detached themselves" because neither myself nor anyone at OAO executed any k8s commands to explicitly detach them. The root cause for the detachment is uncertain.&lt;/li&gt;
&lt;li&gt;The timing of &lt;a href="https://status.cloud.google.com/incident/compute/16011"&gt;this SSD latency incident incident&lt;/a&gt; from the GCE &lt;a href="https://status.cloud.google.com"&gt;status page&lt;/a&gt; seems to coincide with when these detachments happened. I imagine that disks might have had to be detached and reattached as part of whatever Google engineers did to resolve the issue, but that's a guess on my part.&lt;/li&gt;
&lt;li&gt;In any case, while the disks were also automatically reattached, the abrupt disconnection left them in an inconsistent state, so that Postgres instances which use these disk mounts for storage were unable to start due to I/O errors.&lt;/li&gt;
&lt;li&gt;Result: &lt;code&gt;warehouse-postgres&lt;/code&gt; and &lt;code&gt;mart-postgres&lt;/code&gt; instances were down since roughly 22:19.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Resolution&lt;/h3&gt;
&lt;p&gt;Basically, to get things working again, I had to &lt;code&gt;fsck&lt;/code&gt; the affected disks, then detach them from the instances they were attached to with a &lt;code&gt;gcloud&lt;/code&gt; command. So, for example, in the case of the disk &lt;code&gt;mart-data-disk&lt;/code&gt; attached to &lt;code&gt;warehouse-provisioning-1-fde62020-node-8n9r&lt;/code&gt; I had to:&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3
4&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ssh warehouse-provisioning-1-fde62020-node-8n9r &lt;span class="se"&gt;\&lt;/span&gt;
sudo fsck.ext4 -v -y /dev/disk/by-id/google-mart-data-disk
gcloud compute instances detach-disk &lt;span class="se"&gt;\&lt;/span&gt;
gke-warehouse-provisioning-1-fde62020-node-8n9r --disk mart-data-disk
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;Then restart the &lt;code&gt;mart-postgres&lt;/code&gt; as usual with &lt;code&gt;kubectl create -f mart-postgres.yaml&lt;/code&gt;.&lt;/p&gt;</summary></entry><entry><title>Self-referential TODO</title><link href="/self-referential-todo.html" rel="alternate"></link><published>2016-06-23T07:24:35-05:00</published><author><name>Thomas</name></author><id>tag:,2016-06-23:self-referential-todo.html</id><summary type="html">&lt;p&gt;&lt;s&gt;While I want to keeping the styling and build of this page brutally simple, one thing I should consider adding is &lt;a href="http://pygments.org/"&gt;pygments&lt;/a&gt; or similar for code syntax highlighting.&lt;/s&gt; &lt;em&gt;(UPDATE: done!)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;s&gt;Also, look into why &lt;a href="https://github.com/yagermadden/straplessdown"&gt;straplessdown&lt;/a&gt; is stripping inline HTML from the markdown source section. üòï &lt;/s&gt; &lt;em&gt;(UPDATE: wontfix; using Pelican now instead.)&lt;/em&gt;&lt;/p&gt;</summary></entry><entry><title>Distinct line items from DFP line item service</title><link href="/distinct-line-items-from-dfp-line-item-service.html" rel="alternate"></link><published>2016-05-18T00:00:00-05:00</published><author><name>Thomas</name></author><id>tag:,2016-05-18:distinct-line-items-from-dfp-line-item-service.html</id><summary type="html">&lt;p&gt;Over time, the table &lt;code&gt;warehouse_hold.hold_dfp_line_item&lt;/code&gt; has accumulated many rows for each line item. In most cases this is due to changes in the line item configuration or status; it is also due to overlapping attempts to bring the data up-to-date. In any case, Analytics is interested only in the most recent record for each item. As noted in &lt;a href="https://trello.com/c/ygfrMXJr/615-warehouse-etl-investigate-and-fix-line-item-discrepancies-between-dfp-and-hold-dfp-line-item-table"&gt;Trello&lt;/a&gt;, I created a new &lt;code&gt;hold_dfp_line_item_distinct&lt;/code&gt; table, to include one record per line_item_id, based on maximum &lt;code&gt;last_modified_date_time&lt;/code&gt; and &lt;code&gt;created_at&lt;/code&gt; values.&lt;/p&gt;
&lt;p&gt;Oddly (says I), while a CTE defined as&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3
4
5&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;select&lt;/span&gt; &lt;span class="k"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_modified_date_time&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;last_modified_date_time&lt;/span&gt;
     &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;created_at&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;created_at&lt;/span&gt;
     &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line_item_id&lt;/span&gt;
  &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="n"&gt;hold_dfp_line_item&lt;/span&gt;
 &lt;span class="k"&gt;group&lt;/span&gt; &lt;span class="k"&gt;by&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;has the expected number of rows, joining that on all three columns back to the main table resulted in a small number (39 out of about a million) of duplicate rows.&lt;/p&gt;
&lt;p&gt;I have been able to resolve the matter by using &lt;code&gt;select distinct&lt;/code&gt;  in the main query, but I don't understand why it should be necessary.&lt;/p&gt;
&lt;p&gt;Also, as we update with new pulls from the line item service, we'll begin to have multiple rows per line item again, and if this simplified table is desirable in Hold, we'll have to keep refreshing it. Therefore, we will eventually find out whether the duplication of the same line item at the same created_at timestamp was a one-time glitch, or something ongoing. In the former case, we should remove the &lt;code&gt;distinct&lt;/code&gt; from the query, for performance reasons. This note is here as a reminder&lt;/p&gt;</summary></entry><entry><title>Handling fact updates</title><link href="/handling-fact-updates.html" rel="alternate"></link><published>2016-05-11T07:24:35-05:00</published><author><name>Thomas</name></author><id>tag:,2016-05-11:handling-fact-updates.html</id><summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href="http://decisionworks.com/2010/12/design-tip-130-accumulating-snapshots-for-complex-workflows/"&gt;Accumulating snapshot&lt;/a&gt; fact table pattern sounded attractive, but we cannot apply it to our case. It is a way of handling late-arriving facts, but supposes access to the transactional workflow milestone data.&lt;/li&gt;
&lt;li&gt;In our case, DFP is already returning us pre-aggregated snapshot data; they restate the snapshot data over time as more atomic data accumulates on their end.&lt;/li&gt;
&lt;li&gt;For this reason, the best approach will be to reload over a reasonable window to keep our fact table records current with the latest stated values from DFP&lt;/li&gt;
&lt;li&gt;Exact number of days in the window TBD based on analysis of recent re-pulls of data we have already loaded.&lt;/li&gt;
&lt;li&gt;Best guess as of now: 14-day reload window (requires further investigation to rule out first-of-month being exceptional)&lt;/li&gt;
&lt;/ul&gt;</summary></entry><entry><title>Slowly-changing dimension handling for dim_line_item</title><link href="/slowly-changing-dimension-handling-for-dim_line_item.html" rel="alternate"></link><published>2016-05-09T00:00:00-05:00</published><author><name>Thomas</name></author><id>tag:,2016-05-09:slowly-changing-dimension-handling-for-dim_line_item.html</id><summary type="html">&lt;ul&gt;
&lt;li&gt;Hold table load is somewhat incremental already: all modified items get added on to the hold table (not really distinguished from prior versions, but we can use &lt;code&gt;last_modified_date_time&lt;/code&gt; for that)&lt;/li&gt;
&lt;li&gt;So, pull for &lt;code&gt;dim_line_item&lt;/code&gt; update begins by taking all records with most recent &lt;code&gt;created_at&lt;/code&gt; timestamps from &lt;code&gt;hold_dfp_line_item&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;These can be inserted directly to &lt;code&gt;dim_line_item&lt;/code&gt;, with &lt;code&gt;current_date&lt;/code&gt; as &lt;code&gt;effective_dt&lt;/code&gt; and &lt;code&gt;created_at&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Then find &lt;code&gt;line_item_code&lt;/code&gt; values that match newly-inserted rows, with prior &lt;code&gt;created_at&lt;/code&gt; and NULL &lt;code&gt;effective_end_dt&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;update &lt;code&gt;effective_end_dt&lt;/code&gt; of those rows with current_date&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;: treat line_item_code as the fixed SCD key; treat change in any other column as requiring a new record.&lt;/li&gt;
&lt;/ul&gt;</summary></entry></feed>